{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2\n",
    "\n",
    "class FaceDetector:\n",
    "    def __init__(self, faceCascadePath):\n",
    "        self.faceCascade = cv2.CascadeClassifier(faceCascadePath)\n",
    "        \n",
    "    def detect(self, image, scaleFactor = 1.1, minNeighbors = 5, minSize = (30, 30)):\n",
    "        rects = self.faceCascade.detectMultiScale(image, scaleFactor = scaleFactor, minNeighbors =minNeighbors, minSize = minSize, flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "        return rects\n",
    "\n",
    "image_location = './images/obama.png'\n",
    "image = cv2.imread(image_location)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "fd = FaceDetector(\"./cascades/haarcascade_frontalface_default.xml\")\n",
    "faceRects = fd.detect(gray, scaleFactor = 1.1, minNeighbors = 5, minSize = (30, 30))\n",
    "print(\"I found {} face(s)\".format(len(faceRects)))\n",
    "\n",
    "for (x, y, w, h) in faceRects:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "cv2.imshow(\"Faces\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webcam Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2\n",
    "\n",
    "class FaceDetector:\n",
    "    def __init__(self, faceCascadePath):\n",
    "        self.faceCascade = cv2.CascadeClassifier(faceCascadePath)\n",
    "        \n",
    "    def detect(self, image, scaleFactor = 1.1, minNeighbors = 5, minSize = (30, 30)):\n",
    "        rects = self.faceCascade.detectMultiScale(image, scaleFactor = scaleFactor, minNeighbors =minNeighbors, minSize = minSize, flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "        return rects\n",
    "\n",
    "def resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w *r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h *r))\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "    return resized\n",
    "\n",
    "fd = FaceDetector(\"./cascades/haarcascade_frontalface_default.xml\")\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    (grabbed, frame) = camera.read()\n",
    "    if not grabbed:\n",
    "        break\n",
    "    frame = resize(frame, width = 300)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faceRects = fd.detect(gray, scaleFactor = 1.1, minNeighbors = 5, minSize = (30, 30))\n",
    "    #print(\"I found {} face(s)\".format(len(faceRects)))\n",
    "    frameClone = frame.copy()\n",
    "    \n",
    "    for (fX, fY, fW, fH) in faceRects:\n",
    "        cv2.rectangle(frameClone, (fX, fY), (fX + fW, fY + fH), (0, 255, 0), 2)\n",
    "        \n",
    "    cv2.imshow(\"Face\", frameClone)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Tracking in Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "    \n",
    "blueLower = np.array([100, 67, 0], dtype = \"uint8\")\n",
    "blueUpper = np.array([255, 128, 50], dtype = \"uint8\")\n",
    "\n",
    "camera = cv2.VideoCapture('./video/iphonecase.mov')\n",
    "\n",
    "while True:\n",
    "    (grabbed, frame) = camera.read()\n",
    "    \n",
    "    if not grabbed:\n",
    "        break\n",
    "        \n",
    "    blue = cv2.inRange(frame, blueLower, blueUpper)\n",
    "    blue = cv2.GaussianBlur(blue, (3, 3), 0)\n",
    "    (_, cnts, _) = cv2.findContours(blue.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(cnts) > 0:\n",
    "        cnt = sorted(cnts, key = cv2.contourArea, reverse = True)[0]# find the largest contour\n",
    "        \n",
    "        rect = np.int32(cv2.boxPoints(cv2.minAreaRect(cnt)))\n",
    "        cv2.drawContours(frame, [rect], -1, (0, 255, 0), 2)\n",
    "        \n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "    cv2.imshow(\"Binary\", blue)\n",
    "    \n",
    "    time.sleep(0.025)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "    \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eye Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "class EyeTracker:\n",
    "    def __init__(self, faceCascadePath, eyeCascadePath):\n",
    "        self.faceCascade = cv2.CascadeClassifier(faceCascadePath)\n",
    "        self.eyeCascade = cv2.CascadeClassifier(eyeCascadePath)\n",
    "        \n",
    "    def track(self, image):\n",
    "        faceRects = self.faceCascade.detectMultiScale(image, scaleFactor = 1.1, minNeighbors = 5, minSize = (30, 30), flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "        rects = []\n",
    "        for (fX, fY, fW, fH) in faceRects:\n",
    "            faceROI = image[fY:fY + fH, fX:fX + fW]\n",
    "            rects.append((fX, fY, fX + fW, fY + fH))\n",
    "            \n",
    "            eyeRects = self.eyeCascade.detectMultiScale(faceROI, scaleFactor = 1.1, minNeighbors = 10, minSize = (20, 20), flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "            \n",
    "            for (eX, eY, eW, eH) in eyeRects:\n",
    "                rects.append((fX + eX, fY + eY, fX + eX + eW, fY + eY + eH))\n",
    "        return rects\n",
    "    \n",
    "et = EyeTracker(\"./cascades/haarcascade_frontalface_default.xml\", \"./cascades/haarcascade_eye.xml\")\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "def resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w *r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h *r))\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "    return resized\n",
    "\n",
    "while True:\n",
    "    (grabbed, frame) = camera.read()\n",
    "    \n",
    "    if not grabbed:\n",
    "        break\n",
    "    frame = resize(frame, width = 300)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    rects = et.track(gray)\n",
    "    \n",
    "    for rect in rects:\n",
    "        cv2.rectangle(frame, (rect[0], rect[1]), (rect[2], rect[3]), (0, 255, 0), 2)\n",
    "        \n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwriting Recognition with Hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "import mahotas\n",
    "import cv2\n",
    "\n",
    "def resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w *r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h *r))\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "    return resized\n",
    "\n",
    "class HOG:\n",
    "    def __init__(self, orientations = 9, pixelsPerCell = (8, 8), cellsPerBlock = (3, 3), transform = False):\n",
    "        self.orienations = orientations\n",
    "        self.pixelsPerCell = pixelsPerCell\n",
    "        self.cellsPerBlock = cellsPerBlock\n",
    "        self.transform = transform\n",
    "        \n",
    "    def describe(self, image):\n",
    "        hist = feature.hog(image, orientations =self.orienations, pixels_per_cell = self.pixelsPerCell, cells_per_block = self.cellsPerBlock, transform_sqrt = self.transform)\n",
    "        \n",
    "        return hist\n",
    "\n",
    "def load_digits(datasetPath):\n",
    "    data = np.genfromtxt(datasetPath, delimiter = \",\", dtype = \"uint8\")\n",
    "    target = data[:, 0]\n",
    "    data = data[:, 1:].reshape(data.shape[0], 28, 28)\n",
    "    \n",
    "    return (data, target)\n",
    "\n",
    "def deskew(image, width):\n",
    "    (h, w) = image.shape[:2]\n",
    "    moments = cv2.moments(image)\n",
    "    \n",
    "    skew = moments[\"mu11\"] / moments[\"mu02\"]\n",
    "    M = np.float32([[1, skew, -0.5 * w * skew], [0, 1, 0]])\n",
    "    image = cv2.warpAffine(image, M, (w, h), flags = cv2.WARP_INVERSE_MAP | cv2.INTER_LINEAR)\n",
    "    \n",
    "    image = resize(image, width = width)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def center_extent(image, size):\n",
    "    (eW, eH) = size\n",
    "    \n",
    "    if image.shape[1] > image.shape[0]:\n",
    "        image = resize(image, width = eW)\n",
    "    else:\n",
    "        image = resize(image, height = eH)\n",
    "    \n",
    "    extent = np.zeros((eH, eW), dtype = \"uint8\")\n",
    "    offsetX = (eW - image.shape[1]) // 2\n",
    "    offsetY = (eH - image.shape[0]) // 2\n",
    "    extent[offsetY:offsetY + image.shape[0], offsetX:offsetX + image.shape[1]] = image\n",
    "    \n",
    "    CM = mahotas.center_of_mass(extent)\n",
    "    (cY, cX) = np.round(CM).astype(\"int32\")\n",
    "    (dX, dY) = ((size[0] // 2) - cX, (size[1] // 2) - cY)\n",
    "    M = np.float32([[1, 0, dX], [0, 1, dY]])\n",
    "    extent = cv2.warpAffine(extent, M, size)\n",
    "    \n",
    "    return extent\n",
    "\n",
    "#target = []\n",
    "(digits, target) = load_digits(\"./data/digits.csv\")\n",
    "data = []\n",
    "\n",
    "hog = HOG(orientations = 18, pixelsPerCell = (10, 10), cellsPerBlock = (1, 1), transform = True)\n",
    "\n",
    "for image in digits:\n",
    "    image = deskew(image, 20)\n",
    "    image = center_extent(image, (20, 20))\n",
    "    \n",
    "    hist = hog.describe(image)\n",
    "    data.append(hist)\n",
    "\n",
    "model = LinearSVC(random_state = 42)\n",
    "model.fit(data, target)\n",
    "\n",
    "joblib.dump(model, \"./models/svm.cpickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.externals import joblib\n",
    "import mahotas\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import feature\n",
    "\n",
    "def resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w *r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h *r))\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "    return resized\n",
    "\n",
    "class HOG:\n",
    "    def __init__(self, orientations = 9, pixelsPerCell = (8, 8), cellsPerBlock = (3, 3), transform = False):\n",
    "        self.orienations = orientations\n",
    "        self.pixelsPerCell = pixelsPerCell\n",
    "        self.cellsPerBlock = cellsPerBlock\n",
    "        self.transform = transform\n",
    "        \n",
    "    def describe(self, image):\n",
    "        hist = feature.hog(image, orientations =self.orienations, pixels_per_cell = self.pixelsPerCell, cells_per_block = self.cellsPerBlock, transform_sqrt = self.transform)        \n",
    "        return hist\n",
    "\n",
    "def deskew(image, width):\n",
    "    (h, w) = image.shape[:2]\n",
    "    moments = cv2.moments(image)\n",
    "    \n",
    "    skew = moments[\"mu11\"] / moments[\"mu02\"]\n",
    "    M = np.float32([[1, skew, -0.5 * w * skew], [0, 1, 0]])\n",
    "    image = cv2.warpAffine(image, M, (w, h), flags = cv2.WARP_INVERSE_MAP | cv2.INTER_LINEAR)\n",
    "    \n",
    "    image = resize(image, width = width)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def center_extent(image, size):\n",
    "    (eW, eH) = size\n",
    "    \n",
    "    if image.shape[1] > image.shape[0]:\n",
    "        image = resize(image, width = eW)\n",
    "    else:\n",
    "        image = resize(image, height = eH)\n",
    "    \n",
    "    extent = np.zeros((eH, eW), dtype = \"uint8\")\n",
    "    offsetX = (eW - image.shape[1]) // 2\n",
    "    offsetY = (eH - image.shape[0]) // 2\n",
    "    extent[offsetY:offsetY + image.shape[0], offsetX:offsetX + image.shape[1]] = image\n",
    "    \n",
    "    CM = mahotas.center_of_mass(extent)\n",
    "    (cY, cX) = np.round(CM).astype(\"int32\")\n",
    "    (dX, dY) = ((size[0] // 2) - cX, (size[1] // 2) - cY)\n",
    "    M = np.float32([[1, 0, dX], [0, 1, dY]])\n",
    "    extent = cv2.warpAffine(extent, M, size)\n",
    "    \n",
    "    return extent\n",
    "    \n",
    "model = joblib.load(\"./models/svm.cpickle\")\n",
    "\n",
    "hog = HOG(orientations = 18, pixelsPerCell = (10, 10), cellsPerBlock = (1, 1), transform = True)\n",
    "\n",
    "image = cv2.imread(\"./images/number.png\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(blurred, 30, 150)\n",
    "(_, cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cnts = sorted([(c, cv2.boundingRect(c)[0]) for c in cnts], key = lambda x: x[1])\n",
    "print(len(cnts))\n",
    "for (c, _) in cnts:\n",
    "    (x, y, w, h) = cv2.boundingRect(c)\n",
    "    \n",
    "    if w >= 10 and h >= 30:\n",
    "        roi = gray[y:y + h, x:x + w]\n",
    "        thresh = roi.copy()\n",
    "        T = mahotas.thresholding.otsu(roi)\n",
    "        thresh[thresh > T] = 255\n",
    "        thresh = cv2.bitwise_not(thresh)\n",
    "        \n",
    "        thresh = deskew(thresh, 20)\n",
    "        thresh = center_extent(thresh, (20, 20))\n",
    "        \n",
    "        cv2.imshow(\"thresh\", thresh)\n",
    "        \n",
    "        hist = hog.describe(thresh)\n",
    "        digit = model.predict([hist])[0]\n",
    "        print(\"I think that number is: {}\".format(digit))\n",
    "        \n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "        cv2.putText(image, str(digit), (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"image\", image)\n",
    "    cv2.waitKey(0)\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validathttp://localhost:8888/notebooks/Case%20Studies.ipynb#Plant-Classificationion import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "class RGBHistogram:\n",
    "    def __init__(self, bins):\n",
    "        self.bins = bins\n",
    "        \n",
    "    def describe(self, image, mask = None):\n",
    "        hist = cv2.calcHist([image], [0, 1, 2], mask, self.bins, [0, 256, 0, 256, 0, 256])\n",
    "        cv2.normalize(hist, hist)\n",
    "        return hist.flatten()\n",
    "\n",
    "imagePaths = sorted(glob.glob(\"\") + \"/*.png\")\n",
    "maskPaths = sorted(glob.glob(\"\") + \"/*.png\")\n",
    "\n",
    "data = []\n",
    "target = []\n",
    "\n",
    "desc = RGBHistogram([8, 8, 8])\n",
    "\n",
    "for (imagePath, maskPath) in zip(imagePaths, maskPaths):\n",
    "    image = cv2.imread(imagePath)\n",
    "    mask = cv2.imread(maskPath)\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    features = desc.describe(image, mask)\n",
    "    \n",
    "    data.append(features)\n",
    "    target.append(imagePath.split(\"_\")[-2])\n",
    "\n",
    "targetNames = np.unique(target)\n",
    "le = LabelEncoder()\n",
    "target = le.fit_transform(target)\n",
    "\n",
    "(trainData, testData, trainTarget, testTarget) = train_test_split(data, target, test_size = 0.3, random_state = 42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 25, random_state = 84)\n",
    "model.fit(trainData, trainTarget)\n",
    "\n",
    "print(classification_report(testTarget, model.predict(testData), target_names = targetNames))\n",
    "\n",
    "for i in np.random.choice(np.arange(0, len(imagePaths)), 10):\n",
    "    imagePath = imagePaths[i]\n",
    "    maskPath = maskPaths[i]\n",
    "    \n",
    "    image = cv2.imread(imagePath)\n",
    "    mask = cv2.imread(maskPath)\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    features = desc.describe(image, mask)\n",
    "    \n",
    "    flower = le.inverse_transform(model.predict([features]))[0]\n",
    "    print(imagePath)\n",
    "    print(\"I think this flower is a {}\".format(flower.upper()))\n",
    "    cv2.imshow(\"image\", image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
